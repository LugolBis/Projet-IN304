{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supression des caractères spéciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement \n",
    "# Fonction inutilisée !!!!\n",
    "def SuprCaracterSpe(Chaine):  # Prend en entrée une chaine de caractères \n",
    "    ChaineNettoyee = ''\n",
    "    for elem in Chaine:\n",
    "        if (elem.isalnum() == True):\n",
    "            ChaineNettoyee += elem\n",
    "        elif (elem == \"\\ \"[:-1]) and (Chaine.index(elem)<len(Chaine)-2) and (elem + Chaine.index(elem)+1 == '\\n'):\n",
    "            ChaineNettoyee += ' '\n",
    "        else:\n",
    "            ChaineNettoyee += ' '\n",
    "    return ChaineNettoyee     # Renvoie la chaine de cractères sans les caractères spéciaux\n",
    "\n",
    "# Fonctionnalitées manquantes : gestion des mentions et des 'RT pseudo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement \n",
    "\n",
    "def SuprCaracterSpeV2(Chaine):  # Prend en entrée une chaine de caractères \n",
    "    ChaineNettoyee = ''\n",
    "    indice = 0\n",
    "    while indice < len(Chaine):\n",
    "        if (Chaine[indice] == 'R') and (indice < len(Chaine)-2) and (Chaine[indice] + Chaine[indice+1] == 'RT'):\n",
    "            indice += 3\n",
    "            while (indice < len(Chaine)-1) and Chaine[indice] != ' ':\n",
    "                indice+=1\n",
    "            ChaineNettoyee += ' '\n",
    "            indice += 1\n",
    "        elif (Chaine[indice].isalnum() == True):\n",
    "            ChaineNettoyee += Chaine[indice]\n",
    "            indice += 1\n",
    "        elif (Chaine[indice] == \"\\ \"[:-1]) and (indice < len(Chaine)-2) and (Chaine[indice] + Chaine[indice+1] == '\\n'):\n",
    "            ChaineNettoyee += ' '\n",
    "            indice += 1\n",
    "        elif (Chaine[indice] == '@') and (indice < len(Chaine)-2):\n",
    "            indice += 1\n",
    "            while (indice < len(Chaine)-1) and Chaine[indice] != ' ':\n",
    "                indice += 1\n",
    "            ChaineNettoyee += ' '\n",
    "            indice += 1\n",
    "        else:\n",
    "            ChaineNettoyee += ' '\n",
    "            indice += 1\n",
    "    return ChaineNettoyee     # Renvoie la chaine de cractères sans les caractères spéciaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des Données du fichier Json → DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement       \n",
    "# Fonction inutilisée !!!!\n",
    "def RecupDonneesN(NomFichier):\n",
    "    from json import loads \n",
    "    donnees = []   \n",
    "    with open(NomFichier, 'r') as fs, open(r\"C:\\Users\\lddes\\OneDrive\\Bureau\\UVSQ\\L2 Info\\IN304\\Projet\\Zone d’atterrissage.json\", 'w') as fd:\n",
    "        for ligne in fs:\n",
    "            dicoD = loads(ligne)\n",
    "            Tweet = dicoD[\"TweetText\"]\n",
    "            TweetN = SuprCaracterSpeV2(Tweet)\n",
    "            fd.write(f'{TweetN}\\n')\n",
    "            donnees.append(dicoD)\n",
    "        return donnees\n",
    "\n",
    "fichier = r\"C:\\Users\\lddes\\OneDrive\\Bureau\\UVSQ\\L2 Info\\IN304\\Projet\\aitweets.json\"\n",
    "#RecupDonneesN(fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement\n",
    "\n",
    "def RecupDonneesP(NomFichier):  # Prend en entier le nom du fichier à analyser\n",
    "    from pandas import DataFrame\n",
    "    from pandas import merge\n",
    "    from json import loads\n",
    "    with open(NomFichier, 'r') as fs, open(r\"C:\\Users\\lddes\\OneDrive\\Bureau\\UVSQ\\L2 Info\\IN304\\Projet\\Zone d’atterrissage.json\", 'w') as fd:\n",
    "        indice = 0\n",
    "        for ligne in fs:\n",
    "            dicoL = loads(ligne)\n",
    "            Tweet = dicoL[\"TweetText\"]\n",
    "            TweetN = SuprCaracterSpeV2(Tweet)  # Suprime tous les caractères spéciaux, les RT et les pseudonymes\n",
    "            fd.write(f'{TweetN}\\n')     # On écrit le Tweet nettoyé dans \"Zone d’atterrissage.json\"\n",
    "            if indice == 0:\n",
    "                DFF = DataFrame([dicoL])   # On initialise le DatFrame qui va stocker en local les données de la base\n",
    "                indice += 1\n",
    "            else:\n",
    "                DF2 = DataFrame([dicoL])\n",
    "                DFF = DFF.merge(DF2, how='outer')  # On ajoute le dictionnaire de chaque ligne au DataFrame                \n",
    "    return DFF\n",
    "\n",
    "fichier = r\"C:\\Users\\lddes\\OneDrive\\Bureau\\UVSQ\\L2 Info\\IN304\\Projet\\aitweets.json\"\n",
    "DFP = RecupDonneesP(fichier)   # DFP correspond au DataFrame principal, dont les colonnes sont 'id','TweetText', etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opérations d'Analyse\n",
    "Méthode : Récupération des Tweets du DataFrame (pincipal) → Analyse → DataFrame (d'analyse)\n",
    "Les Données d'Analyse seront liées aux données du DataFrame principal par leur index (le numéro de leur ligne tout simplement)\n",
    "\n",
    "Puis pour finir : Fusion des différents DataFrame d'Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les Hashtags ('#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## /!\\  Il manque l'Analyse du Top des '#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement \n",
    "\n",
    "def Hashtags(chaine): # Prend en entrée un str\n",
    "    ListeH = []\n",
    "    SousChaine = chaine.split()  \n",
    "    for elem in SousChaine:\n",
    "        if elem.startswith('#') and len(elem)>1:\n",
    "            ListeH.append(elem)\n",
    "    return ListeH   # Renvoie une liste contenant les # du Tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[#hdatasystems, #Artificia…]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[#MachineLearning, #DataScience, #Python, #AI,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>[#ArtificialIntelligence, #IIoT, #GenerativeAd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>[#ArtificialIntelligence:, #AI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>[#Artificia…]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>[#Healthcare, #A…]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1708 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      #\n",
       "0                                                    []\n",
       "1                          [#hdatasystems, #Artificia…]\n",
       "2                                                    []\n",
       "3                                                    []\n",
       "4     [#MachineLearning, #DataScience, #Python, #AI,...\n",
       "...                                                 ...\n",
       "1703                                                 []\n",
       "1704  [#ArtificialIntelligence, #IIoT, #GenerativeAd...\n",
       "1705                    [#ArtificialIntelligence:, #AI]\n",
       "1706                                      [#Artificia…]\n",
       "1707                                 [#Healthcare, #A…]\n",
       "\n",
       "[1708 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Etat : Fonctionne parfaitement\n",
    "\n",
    "def DFHashtags(DF): # En entrée un DataFrame contenant la colonne des \"TweetText\"\n",
    "    from pandas import DataFrame\n",
    "    from pandas import concat\n",
    "    Taille = DF.shape  # Tuple contenant (le nombre de ligne, le nombre de colonnes)\n",
    "    i = 0\n",
    "    Tweet = DF.loc[i]\n",
    "    ListeHashtags = Hashtags(Tweet)\n",
    "    DFA = DataFrame({'#':[ListeHashtags]}, index=[i])\n",
    "    for i in range(1,Taille[0]):\n",
    "        Tweet = DF.loc[i]\n",
    "        ListeHashtags = Hashtags(Tweet)\n",
    "        DFB = DataFrame({'#':[ListeHashtags]}, index=[i])\n",
    "        DFC = concat([DFA, DFB])\n",
    "        DFA = DFC\n",
    "    return DFA\n",
    "\n",
    "DFHashtags(DFP[\"TweetText\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
