{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supression des caract√®res sp√©ciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement \n",
    "\n",
    "def SuprCaracterSpeV0(Chaine):  # Prend en entr√©e une chaine de caract√®res \n",
    "    ChaineNettoyee = ''\n",
    "    indice = 0\n",
    "    while indice < len(Chaine):\n",
    "        if (Chaine[indice] == 'R') and (indice < len(Chaine)-2) and (Chaine[indice] + Chaine[indice+1] == 'RT'):\n",
    "            indice += 3\n",
    "            while (indice < len(Chaine)-1) and Chaine[indice] != ' ':\n",
    "                indice+=1\n",
    "            ChaineNettoyee += ' '\n",
    "            indice += 1\n",
    "        elif (Chaine[indice].isalnum() == True):\n",
    "            ChaineNettoyee += Chaine[indice]\n",
    "            indice += 1\n",
    "        elif (Chaine[indice] == \"\\ \"[:-1]) and (indice < len(Chaine)-2) and (Chaine[indice] + Chaine[indice+1] == '\\n'):\n",
    "            ChaineNettoyee += ' '\n",
    "            indice += 1\n",
    "        elif (Chaine[indice] == '@') and (indice < len(Chaine)-2):\n",
    "            indice += 1\n",
    "            while (indice < len(Chaine)-1) and Chaine[indice] != ' ':\n",
    "                indice += 1\n",
    "            ChaineNettoyee += ' '\n",
    "            indice += 1\n",
    "        else:\n",
    "            ChaineNettoyee += ' '\n",
    "            indice += 1\n",
    "    return ChaineNettoyee     # Renvoie la chaine de cract√®res sans les caract√®res sp√©ciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement \n",
    "\n",
    "def SuprCaracterSpe(Chaine):  # Prend en entr√©e une chaine de caract√®res \n",
    "    ChaineNettoyee = ''\n",
    "    indice = 0\n",
    "    while indice < len(Chaine):\n",
    "        if (Chaine[indice].isalnum() == True):\n",
    "            ChaineNettoyee += Chaine[indice]\n",
    "            indice += 1\n",
    "        elif (Chaine[indice] == \"\\ \"[:-1]) and (indice < len(Chaine)-2) and (Chaine[indice] + Chaine[indice+1] == '\\n'):\n",
    "            ChaineNettoyee += ' '\n",
    "            indice += 1\n",
    "        else:\n",
    "            ChaineNettoyee += ' '\n",
    "            indice += 1\n",
    "    return ChaineNettoyee     # Renvoie la chaine de cract√®res sans les caract√®res sp√©ciaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seconde fonction 'SuprCaracterSpeV0()' ne retire ni les pseudonymes ni les 'RT' des tweets (ce qui est deux fonctionnalit√©es dont nous avons pris la libert√© de rajouter).\n",
    "J'ai compar√© sur un petit √©chantillon, le temps d'√©xecution de chaque fonction sur la base de donn√©es. Voici les observations not√©es :\n",
    "\n",
    "En appellant simplement la fonction \n",
    "\n",
    "- OP1 : 9.1s, 6.6s, 6.3s\n",
    "- OP2 : 6.5s, 6.4s, 6.3s \n",
    "\n",
    "- OP1 : 6.5s, 6.5s, 6.4s\n",
    "- OP2 : 6.4s, 6.4s, 6.2s\n",
    "\n",
    "En metant 'DFF = RecupDonneesP(fichier)' \n",
    "\n",
    "- OP1 : 6.3s, 6.4s, 6.1s\n",
    "- OP2 : 6.3s, 6.4s, 6.4s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R√©cup√©ration des Donn√©es du fichier Json ‚Üí DataFrame ('DFP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement\n",
    "\n",
    "def ZoneAterrisage(NomFichier):\n",
    "    from json import loads\n",
    "    with open(NomFichier, 'r') as fs, open(r\"C:\\Users\\lddes\\OneDrive\\Bureau\\UVSQ\\L2 Info\\S3\\IN304\\Projet\\Zone d‚Äôatterrissage.json\", 'w') as fd:\n",
    "        for ligne in fs:\n",
    "            dicoL = loads(ligne)\n",
    "            Tweet = dicoL[\"TweetText\"]\n",
    "            TweetN = SuprCaracterSpe(Tweet)  # Suprime tous les caract√®res sp√©ciaux, les RT et les pseudonymes\n",
    "            fd.write(f'{TweetN}\\n')     # On √©crit le Tweet nettoy√© dans \"Zone d‚Äôatterrissage.json\"\n",
    "\n",
    "fichier = r\"C:\\Users\\lddes\\OneDrive\\Bureau\\UVSQ\\L2 Info\\S3\\IN304\\Projet\\aitweets.json\"\n",
    "ZoneAterrisage(fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>AuthorLocation</th>\n",
       "      <th>CreatedAt</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>TweetLanguage</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1415291904850153474</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-14T12:47:39Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>@____bruvteresa_ According to research, NASA c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1415291947560828933</td>\n",
       "      <td>Mysore  and  BERLIN</td>\n",
       "      <td>2021-07-14T12:47:49Z</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @HDataSystems: Artificial Intelligence and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1415291877897605120</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-14T12:47:33Z</td>\n",
       "      <td>246</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @adgpi: Army Technology Board conducted the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1415291886860967940</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-14T12:47:35Z</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @pacorjo: According to a recent survey, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1415291968700264450</td>\n",
       "      <td>Internet</td>\n",
       "      <td>2021-07-14T12:47:54Z</td>\n",
       "      <td>20</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @HarbRimah: Making AI Sing https://t.co/FJo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>1421408743770791938</td>\n",
       "      <td>Liverpool, England</td>\n",
       "      <td>2021-07-31T09:53:47Z</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @innomaticshyd: Top 10 Real world Artificia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>1421424066305605634</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-31T10:54:40Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Iowa State part of U.S. National Science Found...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>1421423882427371521</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>2021-07-31T10:53:57Z</td>\n",
       "      <td>17</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @intellimetri: Human Assisted #ArtificialIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>1421423971858149377</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>2021-07-31T10:54:18Z</td>\n",
       "      <td>12</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @IainLJBrown: Artificial Intelligence learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>1421423964845395969</td>\n",
       "      <td>Torremolinos, Espa√±a</td>\n",
       "      <td>2021-07-31T10:54:16Z</td>\n",
       "      <td>17</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @marcusborba: Artificial Intelligence May F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1708 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id        AuthorLocation             CreatedAt  \\\n",
       "0     1415291904850153474                        2021-07-14T12:47:39Z   \n",
       "1     1415291947560828933   Mysore  and  BERLIN  2021-07-14T12:47:49Z   \n",
       "2     1415291877897605120                        2021-07-14T12:47:33Z   \n",
       "3     1415291886860967940                        2021-07-14T12:47:35Z   \n",
       "4     1415291968700264450              Internet  2021-07-14T12:47:54Z   \n",
       "...                   ...                   ...                   ...   \n",
       "1703  1421408743770791938    Liverpool, England  2021-07-31T09:53:47Z   \n",
       "1704  1421424066305605634                        2021-07-31T10:54:40Z   \n",
       "1705  1421423882427371521             127.0.0.1  2021-07-31T10:53:57Z   \n",
       "1706  1421423971858149377  Singapore, Singapore  2021-07-31T10:54:18Z   \n",
       "1707  1421423964845395969  Torremolinos, Espa√±a  2021-07-31T10:54:16Z   \n",
       "\n",
       "     RetweetCount TweetLanguage  \\\n",
       "0               0            en   \n",
       "1               2            en   \n",
       "2             246            en   \n",
       "3               1            en   \n",
       "4              20            en   \n",
       "...           ...           ...   \n",
       "1703            1            en   \n",
       "1704            0            en   \n",
       "1705           17            en   \n",
       "1706           12            en   \n",
       "1707           17            en   \n",
       "\n",
       "                                              TweetText  \n",
       "0     @____bruvteresa_ According to research, NASA c...  \n",
       "1     RT @HDataSystems: Artificial Intelligence and ...  \n",
       "2     RT @adgpi: Army Technology Board conducted the...  \n",
       "3     RT @pacorjo: According to a recent survey, the...  \n",
       "4     RT @HarbRimah: Making AI Sing https://t.co/FJo...  \n",
       "...                                                 ...  \n",
       "1703  RT @innomaticshyd: Top 10 Real world Artificia...  \n",
       "1704  Iowa State part of U.S. National Science Found...  \n",
       "1705  RT @intellimetri: Human Assisted #ArtificialIn...  \n",
       "1706  RT @IainLJBrown: Artificial Intelligence learn...  \n",
       "1707  RT @marcusborba: Artificial Intelligence May F...  \n",
       "\n",
       "[1708 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Etat : Fonctionne parfaitement\n",
    "\n",
    "def RecupDonneesP(NomFichier):  # Prend en entier le nom du fichier √† analyser\n",
    "    from pandas import DataFrame\n",
    "    from pandas import merge\n",
    "    from json import loads\n",
    "    with open(NomFichier, 'r') as fs, open(r\"C:\\Users\\lddes\\OneDrive\\Bureau\\UVSQ\\L2 Info\\S3\\IN304\\Projet\\Zone d‚Äôatterrissage.json\", 'w') as fd:\n",
    "        ligne = fs.readline()\n",
    "        dicoL = loads(ligne)\n",
    "        DFF = DataFrame([dicoL])   # On initialise le DatFrame qui va stocker en local les donn√©es de la base\n",
    "        for ligne in fs:\n",
    "            dicoL = loads(ligne)\n",
    "            DF2 = DataFrame([dicoL])\n",
    "            DFF = DFF.merge(DF2, how='outer')  # On ajoute le dictionnaire de chaque ligne au DataFrame                \n",
    "    return DFF\n",
    "\n",
    "fichier = r\"C:\\Users\\lddes\\OneDrive\\Bureau\\UVSQ\\L2 Info\\S3\\IN304\\Projet\\aitweets.json\"\n",
    "DFP = RecupDonneesP(fichier)   # DFP correspond au DataFrame principal, dont les colonnes sont 'id','TweetText', etc\n",
    "DFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Op√©rations d'Analyse\n",
    "M√©thode : R√©cup√©ration des Tweets du DataFrame (pincipal) ‚Üí Analyse ‚Üí DataFrame (d'analyse)\n",
    "Les Donn√©es d'Analyse seront li√©es aux donn√©es du DataFrame principal par leur index (le num√©ro de leur ligne tout simplement)\n",
    "\n",
    "Puis pour finir : Fusion des diff√©rents DataFrame d'Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les Hashtags ('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Etat : Fonctionne parfaitement \n",
    "\n",
    "def Hashtags(chaine): # Entr√©e : Cha√Æne de caract√®res\n",
    "    ListeH = []\n",
    "    SousChaine = chaine.split()\n",
    "    for elem in SousChaine:\n",
    "        if elem.startswith('#') and len(elem)>1:\n",
    "            elem2 = ''\n",
    "            indice = 1\n",
    "            while indice < len(elem):\n",
    "                if (elem[indice] == '_') or (elem[indice].isalnum() == True):\n",
    "                    elem2 += elem[indice]\n",
    "                    indice += 1\n",
    "                else:\n",
    "                    indice = len(elem)\n",
    "            ListeH.append(elem[0]+elem2)\n",
    "    return ListeH   # Renvoie une liste contenant les # du Tweet \n",
    "\n",
    "srt = \"RT @INCANDESClLLA: ‚†Ä \\n\\n      for a device upgraded to become the greatest artificial intelligence , ùòΩùôÄùôçùôèùôä squeaked upon the claws threateni‚Ä¶\"\n",
    "Hashtags(srt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DicoHashtags(DF):   # Entr√©e : DataFrame (la colonne des tweets)\n",
    "    DicoH = {}\n",
    "    from pandas import DataFrame\n",
    "    Taille = DF.shape  # Tuple contenant (le nombre de ligne, le nombre de colonnes)\n",
    "    for i in range(Taille[0]):\n",
    "        Tweet = DF.loc[i]\n",
    "        ListeHashtags = Hashtags(Tweet)\n",
    "        for h in ListeHashtags:\n",
    "            if h in DicoH:\n",
    "                nombre = DicoH[h]\n",
    "                nombre +=1\n",
    "                DicoH[h] = nombre\n",
    "            else:\n",
    "                DicoH[h] = 1\n",
    "    del DicoH['#']    # Il y a 33 # incomplets dans la base de donn√©es, ils sont pris en compte par la fonction, on prend donc le soin de suprimer cette cl√© du dico           \n",
    "    return DicoH      # Renvoie un Dictionnaire contenant tous les Hashtags en cl√© et le nombre de fois qu'ils sont tweet√© en valeur\n",
    "\n",
    "DicoH = DicoHashtags(DFP[\"TweetText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement\n",
    "\n",
    "def DFHashtags(DF): # En entr√©e un DataFrame contenant la colonne des \"TweetText\"\n",
    "    from pandas import DataFrame\n",
    "    from pandas import concat\n",
    "    Taille = DF.shape  # Tuple contenant (le nombre de ligne, le nombre de colonnes)\n",
    "    i = 0\n",
    "    Tweet = DF.loc[i]\n",
    "    ListeHashtags = Hashtags(Tweet)\n",
    "    DFA = DataFrame({'#':[ListeHashtags]}, index=[i])\n",
    "    for i in range(1,Taille[0]):\n",
    "        Tweet = DF.loc[i]\n",
    "        ListeHashtags = Hashtags(Tweet)\n",
    "        DFB = DataFrame({'#':[ListeHashtags]}, index=[i])\n",
    "        DFC = concat([DFA, DFB])\n",
    "        DFA = DFC\n",
    "    return DFA\n",
    "\n",
    "DFh = DFHashtags(DFP[\"TweetText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les Arobases @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement \n",
    "\n",
    "def Arobases(chaine): # Prend en entr√©e un str\n",
    "    ListeA = []\n",
    "    SousChaine = chaine.split()\n",
    "    for elem in SousChaine:\n",
    "        if elem.startswith('@') and len(elem)>1:\n",
    "            elem2 = ''\n",
    "            indice = 1\n",
    "            while indice < len(elem):\n",
    "                if (elem[indice] == '_') or (elem[indice].isalnum() == True):\n",
    "                    elem2 += elem[indice]\n",
    "                    indice += 1\n",
    "                else:\n",
    "                    indice = len(elem)\n",
    "            ListeA.append(elem[0]+elem2)\n",
    "    return ListeA   # Renvoie une liste contenant les @ du Tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DicoArobases(DF):   # Entr√©e : DataFrame (la colonne des tweets)\n",
    "    DicoA = {}\n",
    "    from pandas import DataFrame\n",
    "    Taille = DF.shape  # Tuple contenant (le nombre de ligne, le nombre de colonnes)\n",
    "    for i in range(Taille[0]):\n",
    "        Tweet = DF.loc[i]\n",
    "        ListeArobases = Arobases(Tweet)\n",
    "        for h in ListeArobases:\n",
    "            if h in DicoA:\n",
    "                nombre = DicoA[h]\n",
    "                nombre +=1\n",
    "                DicoA[h] = nombre\n",
    "            else:\n",
    "                DicoA[h] = 1 \n",
    "    del DicoA['@']               \n",
    "    return DicoA      # Renvoie un Dictionnaire contenant tous les Hashtags en cl√© et le nombre de fois qu'ils sont tweet√© en valeur\n",
    "\n",
    "DicoA = DicoArobases(DFP[\"TweetText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement\n",
    "\n",
    "def DFArobases(DF): # En entr√©e un DataFrame contenant la colonne des \"TweetText\"\n",
    "    from pandas import DataFrame\n",
    "    from pandas import concat\n",
    "    Taille = DF.shape  # Tuple contenant (le nombre de ligne, le nombre de colonnes)\n",
    "    i = 0\n",
    "    Tweet = DF.loc[i]\n",
    "    ListeArobases = Arobases(Tweet)\n",
    "    DFA = DataFrame({'@':[ListeArobases]}, index=[i])\n",
    "    for i in range(1,Taille[0]):\n",
    "        Tweet = DF.loc[i]\n",
    "        ListeArobases = Arobases(Tweet)\n",
    "        DFB = DataFrame({'@':[ListeArobases]}, index=[i])\n",
    "        DFC = concat([DFA, DFB])\n",
    "        DFA = DFC\n",
    "    return DFA\n",
    "\n",
    "DFa = DFArobases(DFP[\"TweetText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame d'Analyse \n",
    "Ce DataFrame contient toute les Analyses PAR Tweet, il permet de r√©cup√©rer gr√¢ce √† l'index de la ligne du Tweet (stock√© dans le DataFrame principal : 'DFP')\n",
    "les donn√©es d'analyse correspondant au Tweet (les @ mentionn√©s, les # mentionn√©s, les Topiocs mentionn√©s, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- M√©thode n¬∞1\n",
    "\n",
    "On parcour de mani√®re it√©rative le Dataframe en fonction de l'index (le num√©ro de ligne) et on ajoute les op√©rations d'analyses dans un dictionnaire.\n",
    "Puis une fois toutes les lignes analys√©es ont cr√©e un DataFrame √† partir du dictionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement\n",
    "\n",
    "def DataFrameAnalyse(DF):   # En entr√©e un DataFrame contenant la colonne des \"TweetText\"\n",
    "    from pandas import DataFrame\n",
    "    Taille = DF.shape  # Tuple contenant (le nombre de ligne, le nombre de colonnes)\n",
    "    dicoAnalyses = {}\n",
    "    i = 0\n",
    "    Tweet = DF.loc[i]\n",
    "    ListeArobases = Arobases(Tweet)\n",
    "    dicoAnalyses['@'] = [ListeArobases]\n",
    "    ListeHashtags = Hashtags(Tweet)\n",
    "    dicoAnalyses['#'] = [ListeHashtags]\n",
    "    for i in range(1,Taille[0]):\n",
    "        Tweet = DF.loc[i]\n",
    "        ListeArobases = Arobases(Tweet)\n",
    "        dicoAnalyses['@'].append(ListeArobases)\n",
    "        ListeHashtags = Hashtags(Tweet)\n",
    "        dicoAnalyses['#'].append(ListeHashtags)\n",
    "    DFA = DataFrame(dicoAnalyses)\n",
    "    return DFA\n",
    "\n",
    "DFA = DataFrameAnalyse(DFP[\"TweetText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- M√©thode n¬∞2\n",
    "\n",
    "On reprend les Dataframe cr√©er pour chaque Analyses (donc des DataFrame d'une seule colonne) et on les fusionne √† l'aide de la fonction concat()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "DFA2 = concat([DFa, DFh], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctionnalit√©es Supl√©mentaires :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Actualisation manuelle des donn√©es "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat : Fonctionne parfaitement\n",
    "\n",
    "def Refresh():\n",
    "    fichier = r\"C:\\Users\\lddes\\OneDrive\\Bureau\\UVSQ\\L2 Info\\S3\\IN304\\Projet\\aitweets.json\"\n",
    "    ZoneAterrisage(fichier)\n",
    "\n",
    "Refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Le nombre de publications par utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1418403326245306375', '4')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def NbPostUtilisateur(ID) : # En Entr√©e : 'str' (l'ID de l'utilisateur)\n",
    "    global DFP\n",
    "    Taille = DFP.shape\n",
    "    for i in range(Taille[0]):\n",
    "        if DFP[\"id\"].loc[i] == ID:\n",
    "            return (ID, DFP[\"RetweetCount\"].loc[i])  # En sortie : 'tuple' (ID, nombre de Publications)\n",
    "\n",
    "NbPostUtilisateur(\"1418403326245306375\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Le nombre de publications par hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('#AI', 204)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def NbPostHashtags(hashtag): # En entr√©e : 'str'\n",
    "    global DicoH\n",
    "    if hashtag in DicoH:\n",
    "        return (hashtag, DicoH[hashtag])\n",
    "    else:\n",
    "        return (hashtag, 0) # En sortie : 'tuple' (#, nombre de publications dans lequel il est mentionn√©)\n",
    "    \n",
    "NbPostHashtags('#AI')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top K hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Nombre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#ArtificialIntelligence</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#AI</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#MachineLearning</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>#ai</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#DataScience</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#artificialintelligence</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>#BigData</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>#learning</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>#ML</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>#5G</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           #  Nombre\n",
       "11   #ArtificialIntelligence     207\n",
       "5                        #AI     204\n",
       "2           #MachineLearning      86\n",
       "27                       #ai      52\n",
       "3               #DataScience      50\n",
       "10   #artificialintelligence      44\n",
       "49                  #BigData      25\n",
       "16                 #learning      24\n",
       "83                       #ML      23\n",
       "167                      #5G      21"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Etat : Fonctionne IMparfaitement !!!!\n",
    "\n",
    "def TopKH(K):\n",
    "    from pandas import DataFrame\n",
    "    global DicoH\n",
    "    DFKH = DataFrame(DicoH.items(), columns=['#', 'Nombre'])\n",
    "    DFKH = DFKH.sort_values(by='Nombre', ascending=False)  # On Tri le Dataframe selon les valeurs de la deuxi√®me colonne 'Nombre' et on precise 'ascending=False' pour l'ordre d√©croissant\n",
    "    return DFKH.head(K)\n",
    "\n",
    "TopKH(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top K utilisateurs mentionn√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@</th>\n",
       "      <th>Nombre de Mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>@IainLJBrown</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>@Paula_Piccard</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@nigewillson</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>@machinelearnTec</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>@akbarth3great</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>@JoshuaBarbeau</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>@sankrant</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>@SpirosMargaris</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>@machinelearnflx</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>@Datascience__</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    @  Nombre de Mentions\n",
       "26       @IainLJBrown                 112\n",
       "55     @Paula_Piccard                  49\n",
       "18       @nigewillson                  24\n",
       "36   @machinelearnTec                  17\n",
       "284    @akbarth3great                  17\n",
       "680    @JoshuaBarbeau                  17\n",
       "978         @sankrant                  17\n",
       "147   @SpirosMargaris                  16\n",
       "27   @machinelearnflx                  16\n",
       "44     @Datascience__                  15"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Etat : Fonctionne IMparfaitement !!!!\n",
    "\n",
    "def TopKA(K):\n",
    "    from pandas import DataFrame\n",
    "    global DicoA\n",
    "    DFKA = DataFrame(DicoA.items(), columns=['@', 'Nombre de Mentions'])\n",
    "    DFKA = DFKA.sort_values(by='Nombre de Mentions', ascending=False) # On Tri le Dataframe selon les valeurs de la deuxi√®me colonne 'Nombre' et on precise 'ascending=False' pour l'ordre d√©croissant\n",
    "    return DFKA.head(K)\n",
    "\n",
    "TopKA(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probl√®mes !!!\n",
    "\n",
    "- La complexit√©e de la supression des caract√®res sp√©ciaux des tweets pour la Zone d'atterrissage. Le probl√®me √©tant que la m√©thode d'encodage 'utf-8' ne fonctionne pas, ce qui nous force √† parcourir deux fois les cha√Ænes de caract√®res de la base de donn√©es (le fichier Json contenant tous les tweets)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
